# File: frontend/debugiq_dashboard.py

# DebugIQ Dashboard with Code Editor, Diff View, Autonomous Features, and Dedicated Voice Agent

import streamlit as st
import requests
import os
import difflib
from streamlit_ace import st_ace
from streamlit_autorefresh import st_autorefresh

# Imports for Voice Agent section
import av # Required for processing audio frames from streamlit-webrtc
import numpy as np # Required for processing audio frames
import io # Required for in-memory WAV file creation
import wave # Required for WAV file creation
from streamlit_webrtc import webrtc_streamer, WebRtcMode # Also needed if keeping voice
import logging # Already imported by requests, but good to be explicit
import base64 # Needed for voice/image encoding
import re # Needed for GitHub URL parsing
import threading # Potentially needed for thread-safe buffer if issues arise
from urllib.parse import urljoin # Needed for constructing URLs robustly
import json # Needed for parsing JSON error details

# === Logging Setup ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# === Backend Constants ===
# Use environment variable for the backend URL, with a fallback
# Set BACKEND_URL environment variable in Railway frontend settings
BACKEND_URL = os.getenv("BACKEND_URL", "https://debugiq-backend.railway.app") # <-- Ensure this fallback is correct or use env var

# Define API endpoint paths relative to BACKEND_URL
ENDPOINTS = {
Â  Â  "suggest_patch": "/debugiq/suggest_patch",Â  # Correct path for analyze.py endpoint
Â  Â  "qa_validation": "/qa/run", # Based on /qa prefix and @router.post("/run")
Â  Â  "doc_generation": "/doc/generate", # Based on /doc prefix and @router.post("/generate")
Â  Â  "issues_inbox": "/issues/attention-needed", # Based on no prefix and @router.get("/issues/attention-needed")
Â  Â  "workflow_run": "/workflow/run_autonomous_workflow", # Based on /workflow prefix and @router.post("/run_autonomous_workflow")
    # Workflow status needs issue_id formatting
Â  Â  "workflow_status": "/issues/{issue_id}/status", # Based on no prefix and @router.get("/issues/{issue_id}/status")
Â  Â  "system_metrics": "/metrics/status", # Based on no prefix and @router.get("/metrics/status")
Â  Â  # Paths for Voice/Gemini - CONFIRM THESE WITH YOUR BACKEND ROUTERS
Â  Â  "voice_transcribe": "/voice/transcribe", # Example path - CHECK YOUR BACKEND
Â  Â  "gemini_chat": "/gemini/chat", # Example path - CHECK YOUR BACKEND
Â  Â  "tts": "/voice/tts"Â  # Example path - CHECK YOUR BACKEND
}


# === Helper Functions ===
# Modified make_api_request to construct the full URL from BACKEND_URL and path
def make_api_request(method, endpoint_key, payload=None, return_json=True): # Takes endpoint_key, not full url
Â  Â  """Makes an API request to the backend."""
    # Ensure endpoint_key exists in ENDPOINTS
    if endpoint_key not in ENDPOINTS:
        logger.error(f"Invalid endpoint key: {endpoint_key}")
        return {"error": f"Frontend configuration error: Invalid endpoint key '{endpoint_key}'."}

    # Handle endpoints that require formatting (like workflow_status)
    path_template = ENDPOINTS[endpoint_key]

    # --- Construct the path ---
    # This needs to be smarter if other endpoints require formatting.
    # For now, handle workflow_status specifically.
    if endpoint_key == "workflow_status":
         issue_id = st.session_state.get("active_issue_id")
         if not issue_id:
              logger.error("Workflow status requested but no active_issue_id in session state.")
              # Indicate that polling should stop if no issue_id
              st.session_state.workflow_completed = True
              return {"error": "No active issue ID to check workflow status."}
         try:
            # Format the path using the issue_id
            path = path_template.format(issue_id=issue_id)
         except KeyError as e:
             logger.error(f"Failed to format workflow_status path: Missing key {e}")
             st.session_state.workflow_completed = True
             return {"error": f"Internal error formatting workflow status URL: Missing issue ID key."}
    else:
         # For all other endpoints, the path is static from ENDPOINTS
         path = path_template

    # Construct the full URL by joining BACKEND_URL and the path
    # Use urljoin for robust joining, especially if BACKEND_URL might or might not end with /
Â  Â  url = urljoin(BACKEND_URL, path) # <--- CONSTRUCT THE FULL URL HERE

Â  Â  try:
Â  Â  Â  Â  logger.info(f"Making API request: {method} {url}")
Â  Â  Â  Â  # Set a reasonable timeout for API calls
Â  Â  Â  Â  response = requests.request(method, url, json=payload, timeout=60) # Pass the constructed url
Â  Â  Â  Â  response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
Â  Â  Â  Â  logger.info(f"API request successful: {method} {url}")
Â  Â  Â  Â  if return_json:
Â  Â  Â  Â  Â  Â  return response.json()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  return response.content # Return raw content for binary data like audio
Â  Â  except requests.exceptions.Timeout:
Â  Â  Â  Â  logger.error(f"API request timed out: {method} {url}")
Â  Â  Â  Â  return {"error": "API request timed out. The backend might be slow or unresponsive."}
Â  Â  except requests.exceptions.ConnectionError:
Â  Â  Â  Â  logger.error(f"API connection error: {method} {url}")
Â  Â  Â  Â  return {"error": "Could not connect to the backend API. Please check the backend URL and status."}
Â  Â  except requests.exceptions.RequestException as e:
Â  Â  Â  Â  logger.error(f"API request failed: {e}")
        # Try to include backend error detail if available
        detail = str(e)
        backend_detail = "N/A"
        if e.response is not None:
            detail = f"Status {e.response.status_code}"
            try:
                 # Attempt to parse JSON detail from backend
                 backend_json = e.response.json()
                 backend_detail = backend_json.get('detail', backend_json)
                 # Include validation errors if available (e.g., FastAPI 422)
                 if isinstance(backend_detail, list) and all(isinstance(item, dict) for item in backend_detail):
                     backend_detail_str = json.dumps(backend_detail, indent=2)
                 elif isinstance(backend_detail, dict):
                      backend_detail_str = json.dumps(backend_detail, indent=2)
                 else:
                      backend_detail_str = str(backend_detail)

                 detail = f"Status {e.response.status_code} - Backend Detail: {backend_detail_str}" # More informative error

            except json.JSONDecodeError:
                 # If not JSON, include raw text
                 backend_detail = e.response.text
                 detail = f"Status {e.response.status_code} - Response Text: {backend_detail}"
            except Exception as json_e:
                 logger.warning(f"Could not parse backend error response as JSON: {json_e}")


        return {"error": f"API request failed: {detail}", "backend_detail": backend_detail}


# === Audio Processing Helper ===
def frames_to_wav_bytes(frames):
Â  Â  """Converts a list of audio frames (av.AudioFrame) to WAV formatted bytes."""
Â  Â  if not frames:
Â  Â  Â  Â  return None

Â  Â  logger.info(f"Attempting to convert {len(frames)} audio frames to WAV.")

Â  Â  # Assume consistent format across frames
Â  Â  try:
Â  Â  Â  Â  frame_0 = frames[0]
Â  Â  Â  Â  sample_rate = frame_0.sample_rate
Â  Â  Â  Â  format_name = frame_0.format.name
Â  Â  Â  Â  channels = frame_0.layout.channels
Â  Â  Â  Â  sample_width_bytes = frame_0.format.bytes # Bytes per sample per channel
Â  Â  Â  Â  logger.info(f"Detected audio format: {format_name}, channels: {channels}, sample_rate: {sample_rate}, sample_width: {sample_width_bytes} bytes.")
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"Error accessing frame properties: {e}")
Â  Â  Â  Â  return None

Â  Â  # Check for common formats and convert to raw bytes
Â  Â  # streamlit-webrtc typically provides s16, s32p, or f32p
Â  Â  # s16 is signed 16-bit int, interleaved
Â  Â  if 's16' in format_name and frame_0.layout.name in ['mono', 'stereo']:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  # For s16 interleaved, data is in the first plane. Concatenate raw bytes.
Â  Â  Â  Â  Â  Â  all_bytes = b"".join([frame.planes[0].buffer.tobytes() for frame in frames])
Â  Â  Â  Â  Â  Â  logger.info(f"Concatenated raw bytes from frames, total size: {len(all_bytes)} bytes.")
Â  Â  Â  Â  Â  Â  raw_data = all_bytes
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â logger.error(f"Error concatenating s16 audio frame bytes: {e}")
Â  Â  Â  Â  Â  Â  Â return None
Â  Â  elif 's32p' in format_name or 'f32p' in format_name:
Â  Â  Â  Â  Â # Planar formats: data for each channel is in a separate plane. Need to interleave.
Â  Â  Â  Â  Â try:
Â  Â  Â  Â  Â  Â  Â # Convert planes to numpy arrays and interleave
Â  Â  Â  Â  Â  Â  Â all_channels_data = [np.concatenate([frame.planes[i].to_ndarray() for frame in frames]) for i in range(channels)]
Â  Â  Â  Â  Â  Â  Â # Stack channel data (e.g., [samples_ch1], [samples_ch2]) -> [[s1_ch1, s1_ch2], [s2_ch1, s2_ch2], ...]
Â  Â  Â  Â  Â  Â  Â interleaved_data = np.stack(all_channels_data, axis=-1)
Â  Â  Â  Â  Â  Â  Â raw_data = interleaved_data.tobytes()
Â  Â  Â  Â  Â  Â  Â logger.info(f"Interleaved planar data, resulting in {len(raw_data)} bytes.")
Â  Â  Â  Â  Â except Exception as e:
Â  Â  Â  Â  Â  Â  Â logger.error(f"Error processing planar audio frames: {e}")
Â  Â  Â  Â  Â  Â  Â return None
Â  Â  else:
Â  Â  Â  Â  logger.error(f"Unsupported audio format or layout for WAV conversion: {format_name}, {frame_0.layout.name}. Support for s16, s32p, f32p (mono/stereo) implemented.")
Â  Â  Â  Â  return None


Â  Â  # Create a WAV file in memory
Â  Â  try:
Â  Â  Â  Â  with io.BytesIO() as wav_buffer:
Â  Â  Â  Â  Â  Â  with wave.open(wav_buffer, 'wb') as wf:
Â  Â  Â  Â  Â  Â  Â  Â  wf.setnchannels(channels)
Â  Â  Â  Â  Â  Â  Â  Â  wf.setsampwidth(sample_width_bytes)
Â  Â  Â  Â  Â  Â  Â  Â  wf.setframerate(sample_rate)
Â  Â  Â  Â  Â  Â  Â  Â  wf.writeframes(raw_data)
Â  Â  Â  Â  Â  Â  wav_bytes = wav_buffer.getvalue()
Â  Â  Â  Â  Â  Â  logger.info(f"Successfully created WAV data of size {len(wav_bytes)} bytes.")
Â  Â  Â  Â  Â  Â  return wav_bytes
Â  Â  except Exception as e:
Â  Â  Â  Â  logger.error(f"Error creating WAV file: {e}")
Â  Â  Â  Â  return None

# === WebRTC Audio Frame Callback ===
# Moved this function definition to the top level to ensure it's defined before use
def audio_frame_callback(frame: av.AudioFrame):
Â  Â  """Callback function to receive and process audio frames from the browser."""
Â  Â  # Use a thread-safe buffer to handle audio frames received in a different thread
Â  Â  if "audio_buffer" not in st.session_state:
Â  Â  Â  Â  st.session_state.audio_buffer = []

Â  Â  # Lock to ensure thread-safe access to session state from the callback thread
Â  Â  if "audio_buffer_lock" not in st.session_state:
Â  Â  Â  Â  st.session_state.audio_buffer_lock = threading.Lock()

Â  Â  with st.session_state.audio_buffer_lock:
Â  Â  Â  Â  if st.session_state.get('is_recording', False):
Â  Â  Â  Â  Â  Â  # Append the audio frame to the session state's buffer
Â  Â  Â  Â  Â  Â  st.session_state.audio_buffer.append(frame)

Â  Â  Â  Â  Â  Â  # Store format info from the first frame if not already stored and buffer is not empty
Â  Â  Â  Â  Â  Â  if 'audio_format' not in st.session_state and st.session_state.audio_buffer:
Â  Â  Â  Â  Â  Â  Â  Â  frame_0 = st.session_state.audio_buffer[0]
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.audio_format = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'sample_rate': frame_0.sample_rate,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'format_name': frame_0.format.name,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'channels': frame_0.layout.channels,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'sample_width_bytes': frame_0.format.bytes
Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  # Log the audio frame details for debugging purposes (optional, can be chatty)
Â  Â  Â  Â  Â  Â  # print(f"Audio frame received: {len(st.session_state.audio_buffer)} frames buffered.")


# === Main Application ===
st.set_page_config(page_title="DebugIQ Dashboard", layout="wide")
st.title("ğŸ§  DebugIQ ")

# Initialize session state for recording and chat history
if 'is_recording' not in st.session_state:
Â  Â  st.session_state.is_recording = False
if 'audio_buffer' not in st.session_state:
Â  Â  st.session_state.audio_buffer = []
if 'audio_buffer_lock' not in st.session_state:
Â  Â  st.session_state.audio_buffer_lock = threading.Lock() # Initialize the lock
if 'recording_status' not in st.session_state:
Â  Â  st.session_state.recording_status = "Idle"
if 'chat_history' not in st.session_state:
Â  Â  st.session_state.chat_history = [] # Store list of {"role": "user" or "ai", "content": "...", "audio": b"..."}
# No longer need last_audio_response as audio is stored in chat_history

# === Sidebar for GitHub Integration ===
st.sidebar.header("ğŸ“¦ GitHub Integration")
github_url = st.sidebar.text_input("GitHub Repository URL", placeholder="https://github.com/owner/repo", key="sidebar_github_url")
if github_url:
Â  Â  match = re.match(r"https://github\.com/([^/]+)/([^/]+)", github_url)
Â  Â  if match:
Â  Â  Â  Â  owner, repo = match.groups()
Â  Â  Â  Â  st.sidebar.success(f"**Repository:** {repo} (Owner: {owner})")
Â  Â  else:
Â  Â  Â  Â  st.sidebar.error("Invalid GitHub URL.")

# === Application Tabs ===
# Removed Voice Agent tab as it's now a dedicated section
# Ensure tab count and names match your desired UI
tabs = st.tabs(["ğŸ“„ Traceback + Patch", "âœ… QA Validation", "ğŸ“˜ Documentation", "ğŸ“£ Issues", "ğŸ¤– Workflow", "ğŸ” Workflow Status", "ğŸ“ˆ Metrics"])
# Assign tabs to variables based on their index
tab_trace, tab_qa, tab_doc, tab_issues, tab_workflow, tab_status, tab_metrics = tabs

# === Traceback + Patch Tab ===
with tab_trace:
Â  Â  st.header("ğŸ“„ Traceback & Patch Analysis")
    # Updated file uploader types based on backend model
Â  Â  uploaded_file = st.file_uploader("Upload Traceback or Source Files", type=["txt", "py", "java", "js", "cpp", "c"], key="trace_file_uploader")

Â  Â  if uploaded_file:
Â  Â  Â  Â  file_content = uploaded_file.read().decode("utf-8")
Â  Â  Â  Â  # Display original code - using st.code is better for syntax highlighting
Â  Â  Â  Â  st.subheader("Original Code")
        # Attempt to guess language from file type
        original_language = uploaded_file.type.split('/')[-1] if uploaded_file.type in ["py", "java", "js", "cpp", "c"] else "plaintext"
Â  Â  Â  Â  st.code(file_content, language=original_language, height=300)

Â  Â  Â  Â  if st.button("ğŸ”¬ Analyze & Suggest Patch", key="analyze_patch_btn"):
Â  Â  Â  Â  Â  Â  with st.spinner("Analyzing and suggesting patch..."):
Â  Â  Â  Â  Â  Â  Â  Â  # Corrected Payload to match backend AnalyzeRequest model
Â  Â  Â  Â  Â  Â  Â  Â  # Requires 'code', 'language', (optional 'context')
Â  Â  Â  Â  Â  Â  Â  Â  payload = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "code": file_content,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "language": original_language, # Use detected language
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # "context": {} # <--- Add optional context if needed by backend
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  # Use make_api_request with the endpoint key
Â  Â  Â  Â  Â  Â  Â  Â  response = make_api_request("POST", "suggest_patch", payload) # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  Â  Â  # Assumes backend returns 'diff' and 'explanation' keys
Â  Â  Â  Â  Â  Â  Â  Â  suggested_diff = response.get("diff", "No diff suggested.")
Â  Â  Â  Â  Â  Â  Â  Â  explanation = response.get("explanation", "No explanation provided.")

Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Suggested Patch")
Â  Â  Â  Â  Â  Â  Â  Â  # Display diff with diff language highlighting
Â  Â  Â  Â  Â  Â  Â  Â  st.code(suggested_diff, language="diff", height=300)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"ğŸ’¡ **Explanation:** {explanation}")


Â  Â  Â  Â  Â  Â  Â  Â  # Code Editor for Editing Patch
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("### âœï¸ Edit Suggested Patch")
Â  Â  Â  Â  Â  Â  Â  Â  edited_patch = st_ace(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value=suggested_diff, # Start with the suggested diff
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  language=original_language, # Use original language for editing
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  theme="monokai",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  height=350,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key="ace_editor_patch" # Unique key
Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  Â  Â  # Diff View (Original vs. Edited Patch)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ” Diff View (Original vs. Edited Patch)")
                # Check if both original code and edited patch are available
Â  Â  Â  Â  Â  Â  Â  Â  if edited_patch is not None and file_content is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Generate diff as HTML
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  diff_html = difflib.HtmlDiff(wrapcolumn=80).make_table(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fromlines=file_content.splitlines(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tolines=edited_patch.splitlines(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fromdesc="Original Code",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  todesc="Edited Patch",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  context=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Display HTML in Streamlit
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.components.v1.html(diff_html, height=400, scrolling=True) # Adjusted height
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Upload original code and generate/edit patch to see diff.")

Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Display error from make_api_request helper
Â  Â  Â  Â  Â  Â  Â  Â  st.error(response["error"])
                # Optionally display backend detail if available
                if "backend_detail" in response and response["backend_detail"] not in ["N/A", "", response["error"].split(" - ", 1)[-1]]:
                     st.json({"Backend Detail": response["backend_detail"]})


# === QA Validation Tab ===
with tab_qa:
Â  Â  st.header("âœ… QA Validation")
Â  Â  st.write("Upload a patch file to run QA validation checks.")
Â  Â  uploaded_patch = st.file_uploader("Upload Patch File", type=["txt", "diff", "patch"], key="qa_patch_uploader")

Â  Â  if uploaded_patch:
Â  Â  Â  Â  patch_content = uploaded_patch.read().decode("utf-8")
Â  Â  Â  Â  st.subheader("Patch Content")
Â  Â  Â  Â  st.code(patch_content, language="diff", height=200)

Â  Â  if st.button("ğŸ›¡ï¸ Validate Patch", key="qa_validate_btn"):
Â  Â  Â  Â  if uploaded_patch:
Â  Â  Â  Â  Â  Â  with st.spinner("Running QA validation..."):
                    # Check your backend's expected payload for /qa/run
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  payload = {"patch_diff": patch_content} # Assuming backend expects 'patch_diff'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  response = make_api_request("POST", "qa_validation", payload) # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Validation Results")
Â  Â  Â  Â  Â  Â  Â  Â  # Display validation results - check backend response format
Â  Â  Â  Â  Â  Â  Â  Â  st.json(response) # Assuming response is a JSON summary/report
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(response["error"])
                if "backend_detail" in response: st.json({"Backend Detail": response["backend_detail"]})
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Please upload a patch file first.")


# === Documentation Tab ===
with tab_doc:
Â  Â  st.header("ğŸ“˜ Documentation Generation")
Â  Â  st.write("Upload a code file to generate documentation automatically.")
Â  Â  uploaded_code = st.file_uploader("Upload Code File for Documentation", type=["txt", "py", "java", "js", "cpp", "c"], key="doc_code_uploader")

Â  Â  if uploaded_code:
Â  Â  Â  Â  code_content = uploaded_code.read().decode("utf-8")
Â  Â  Â  Â  st.subheader("Code Content")
        doc_language = uploaded_code.type.split('/')[-1] if uploaded_code.type in ["py", "java", "js", "cpp", "c"] else "plaintext"
Â  Â  Â  Â  st.code(code_content, language=doc_language, height=200)

Â  Â  if st.button("ğŸ“ Generate Documentation", key="doc_generate_btn"):
Â  Â  Â  Â  if uploaded_code:
Â  Â  Â  Â  Â  Â  with st.spinner("Generating documentation..."):
                # Check your backend's expected payload for /doc/generate
Â  Â  Â  Â  Â  Â  Â  Â  payload = {"code": code_content, "language": doc_language} # Assuming backend needs code and language
Â  Â  Â  Â  Â  Â  Â  Â  response = make_api_request("POST", "doc_generation", payload) # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  Â  Â  # Assuming the response contains a "documentation" key with markdown or text
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Generated Documentation")
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(response.get("documentation", "No documentation generated."))
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(response["error"])
                if "backend_detail" in response: st.json({"Backend Detail": response["backend_detail"]})
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Please upload a code file first.")


# === Issues Tab ===
with tab_issues:
Â  Â  st.header("ğŸ“£ Issues Inbox")
Â  Â  st.write("This section lists issues needing attention from the autonomous workflow.")

Â  Â  if st.button("ğŸ”„ Refresh Issues", key="issues_refresh_btn"):
Â  Â  Â  Â  with st.spinner("Fetching issues..."):
Â  Â  Â  Â  Â  Â  response = make_api_request("GET", "issues_inbox") # <--- Use endpoint key

Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  if response.get("issues"):
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("Issues Needing Attention")
                # Display issues - check backend response format
                # Assuming backend returns {"issues": [{"id": ..., "status": ..., "error_message": ...}, ...]}
Â  Â  Â  Â  Â  Â  Â  Â  for issue in response.get("issues", []):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander(f"Issue ID: {issue.get('id', 'N/A')} - Status: {issue.get('status', 'Unknown Status')}"):
                        st.write(f"**Error Details:** {issue.get('error_message', 'No error details provided.')}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # You might add more issue details here if provided by the backend
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â st.info("No issues needing attention found.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error(response["error"])
            if "backend_detail" in response: st.json({"Backend Detail": response["backend_detail"]})


# === Workflow Tab (Trigger) ===
with tab_workflow:
Â  Â  st.header("ğŸ¤– Autonomous Workflow Trigger")
Â  Â  st.write("Trigger an autonomous workflow run for a specific issue.")
Â  Â  issue_id = st.text_input("Issue ID to Trigger Workflow", placeholder="e.g., BUG-123", key="workflow_trigger_issue_id")

Â  Â  if st.button("â–¶ï¸ Trigger Workflow", key="workflow_trigger_btn"):
Â  Â  Â  Â  if issue_id:
Â  Â  Â  Â  Â  Â  with st.spinner(f"Triggering workflow for issue {issue_id}..."):
                # Check backend payload for /workflow/run_autonomous_workflow
Â  Â  Â  Â  Â  Â  Â  Â  payload = {"issue_id": issue_id} # Assuming backend expects 'issue_id'
Â  Â  Â  Â  Â  Â  Â  Â  response = make_api_request("POST", "workflow_run", payload) # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"Workflow triggered successfully for Issue {issue_id}. Response: {response.get('message', 'No message.')}")
                # Store the issue_id to enable status polling in the next tab
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.active_issue_id = issue_id
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.workflow_completed = False # Reset completed state to start polling
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(response["error"])
                if "backend_detail" in response: st.json({"Backend Detail": response["backend_detail"]})
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("Please enter an Issue ID.")

# === Workflow Check Tab (Status/Polling) ===
# Updated this tab name to better reflect its primary function (status/polling)
with tab_status: # This is now the status/polling tab
Â  Â  st.header("ğŸ” Autonomous Workflow Status")
    # Add a text input to manually set the issue ID to poll
Â  Â  issue_id_for_polling = st.text_input("Issue ID to check status (leave blank if triggered workflow above)", placeholder="e.g., BUG-123", key="workflow_status_issue_id")

Â  Â  # If manually entered issue_id, use it for polling
Â  Â  if issue_id_for_polling:
Â  Â  Â  Â  st.session_state.active_issue_id = issue_id_for_polling
Â  Â  Â  Â  st.session_state.workflow_completed = False # Assume not completed if manually set


Â  Â  st.write("Checking status for Issue ID:", st.session_state.active_issue_id or "None (Trigger workflow or enter ID above)")

Â  Â  # Progress tracker logic (kept as is)
Â  Â  progress_labels = [
Â  Â  Â  Â  "ğŸ§¾ Fetching Details",
Â  Â  Â  Â  "ğŸ•µï¸ Diagnosis",
Â  Â  Â  Â  "ğŸ›  Patch Suggestion",
Â  Â  Â  Â  "ğŸ”¬ Patch Validation",
Â  Â  Â  Â  "âœ… Patch Confirmed", # This status name might need adjustment based on backend
Â  Â  Â  Â  "ğŸ“¦ PR Created" # This status name might need adjustment based on backend
Â  Â  ]
Â  Â  progress_map = {
Â  Â  Â  Â  "Seeded": 0, # Assuming Seeded is initial status
Â  Â  Â  Â  "Fetching Details": 0,
Â  Â  Â  Â  "Diagnosis in Progress": 1,
Â  Â  Â  Â  "Diagnosis Complete": 1, # Add complete status to map
Â  Â  Â  Â  "Patch Suggestion in Progress": 2,
Â  Â  Â  Â  "Patch Suggestion Complete": 2, # Add complete status to map
Â  Â  Â  Â  "Patch Validation in Progress": 3,
Â  Â  Â  Â  "Patch Validated": 4,
Â  Â  Â  Â  "PR Creation in Progress": 5, # Add PR creation status
Â  Â  Â  Â  "PR Created - Awaiting Review/QA": 5 # Correct terminal status
Â  Â  }
Â  Â  terminal_status = "PR Created - Awaiting Review/QA"
Â  Â  failed_status = "Workflow Failed"


Â  Â  def show_agent_progress(status):
Â  Â  Â  Â  step = progress_map.get(status, 0)
Â  Â  Â  Â  # Adjust icon logic: success up to current step, spinner for current, empty for future
        if status == failed_status:
            icon = "âŒ"
            st.markdown(f"{icon} Workflow Failed")
        else:
            st.progress((step + 1) / len(progress_labels))
            for i, label in enumerate(progress_labels):
                 icon = "âœ…" if i <= step else ("ğŸ”„" if i == step + 1 else "â³") # Spinner for the *next* step
                 st.markdown(f"{icon} {label}")


Â  Â  # Polling logic (autorefresh only if an issue is active and workflow not complete)
Â  Â  if st.session_state.active_issue_id and not st.session_state.workflow_completed:
Â  Â  Â  Â  logger.info(f"Polling status for issue: {st.session_state.active_issue_id}")
Â  Â  Â  Â  # Autorefresh triggers a rerun every X milliseconds
Â  Â  Â  Â  st_autorefresh(interval=2000, key=f"workflow-refresh-{st.session_state.active_issue_id}") # Unique key per issue


Â  Â  # --- Fetch and Display Status ---
Â  Â  # This code runs on every rerun, including those triggered by autorefresh
Â  Â  if st.session_state.active_issue_id and not st.session_state.workflow_completed: # Only fetch if active and not completed yet
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  # Use make_api_request with the endpoint key - special handling in make_api_request for formatting
Â  Â  Â  Â  Â  Â  status_response = make_api_request("GET", "workflow_status") # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  if "error" not in status_response:
Â  Â  Â  Â  Â  Â  Â  Â  # Assumes backend returns {"status": "...", "error_message": "..."}
Â  Â  Â  Â  Â  Â  Â  Â  current_status = status_response.get("status", "Unknown")
Â  Â  Â  Â  Â  Â  Â  Â  error_message = status_response.get("error_message")

Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.last_status = current_status # Store last status
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"ğŸ” Live Status: **{current_status}**")

Â  Â  Â  Â  Â  Â  Â  Â  if error_message:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Workflow Error: {error_message}")

Â  Â  Â  Â  Â  Â  Â  Â  show_agent_progress(current_status) # Update progress bar and labels

Â  Â  Â  Â  Â  Â  Â  Â  # Check if workflow has reached a terminal state (completed or failed)
Â  Â  Â  Â  Â  Â  Â  Â  if current_status == terminal_status or current_status == failed_status:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.workflow_completed = True # Stop polling
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if current_status == terminal_status:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("âœ… DebugIQ agents completed full cycle.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: # Workflow Failed
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("âŒ DebugIQ workflow failed.")

Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Handle API request errors (e.g., 404 if issue ID not found)
Â  Â  Â  Â  Â  Â  Â  Â  st.error(status_response["error"])
                if "backend_detail" in status_response: st.json({"Backend Detail": status_response["backend_detail"]})
Â  Â  Â  Â  Â  Â  Â  Â  # Stop polling on API errors
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.workflow_completed = True

Â  Â  else: # Display idle status if no issue ID is active or if workflow is completed
Â  Â  Â  Â  if st.session_state.last_status: # Show final status if completed
             if st.session_state.last_status == terminal_status:
                 st.success("âœ… Workflow completed.")
             elif st.session_state.last_status == failed_status:
                 st.error("âŒ Workflow failed.")
                 # Display last known error message if available
                 if "error_message" in st.session_state:
                     st.error(f"Last recorded error: {st.session_state.error_message}")
             else: # Handle other non-polling terminal states
                 st.info(f"Workflow finished with status: **{st.session_state.last_status}**")
             # Optionally show final progress state
             show_agent_progress(st.session_state.last_status)

Â  Â  Â  Â  else: # No active issue and no last status
Â  Â  Â  Â  Â  Â  st.info("Enter an Issue ID or trigger a workflow to see status.")

Â  Â  Â  Â  # Ensure polling is off if no active ID or workflow is completed
Â  Â  Â  Â  st.session_state.workflow_completed = True # Explicitly set completed if no active ID


# === Metrics Tab ===
with tab_metrics:
Â  Â  st.header("ğŸ“ˆ System Metrics")
Â  Â  st.write("View system and performance metrics for the DebugIQ backend.")

Â  Â  if st.button("ğŸ“Š Fetch Metrics", key="metrics_fetch_btn"):
Â  Â  Â  Â  with st.spinner("Fetching system metrics..."):
Â  Â  Â  Â  Â  Â  response = make_api_request("GET", "system_metrics") # <--- Use endpoint key

Â  Â  Â  Â  if "error" not in response:
Â  Â  Â  Â  Â  Â  st.subheader("Backend System Metrics")
Â  Â  Â  Â  Â  Â  # Display metrics - check backend response format
Â  Â  Â  Â  Â  Â  st.json(response) # Assuming response is a JSON dictionary
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error(response["error"])
            if "backend_detail" in response: st.json({"Backend Detail": response["backend_detail"]})


# === DebugIQ Voice Agent Section (Dedicated Section at the bottom) ===
st.markdown("---") # Add a separator below the tabs
st.markdown("---") # Add another separator for clear visual distinction
st.header("ğŸ™ï¸ DebugIQ Voice Agent")
st.write("Interact conversationally with DebugIQ using your voice or text. Ask questions or give commands related to debugging tasks.")
st.write("You can ask things like: 'Analyze the traceback', 'Generate documentation for this code', or ask general programming questions.") # Guide the user

# Display chat history
chat_container = st.container(height=400) # Use a container for chat history with a fixed height and scroll
with chat_container:
Â  Â  for message in st.session_state.chat_history:
Â  Â  Â  Â  role = "ğŸ‘¤ User" if message["role"] == "user" else "ğŸ¤– AI"
Â  Â  Â  Â  st.markdown(f"**{role}:** {message['content']}")
Â  Â  Â  Â  # Add play button or automatically play AI audio response
Â  Â  Â  Â  if message["role"] == "ai" and message.get("audio"):
Â  Â  Â  Â  Â  Â  Â # Use a unique key for each audio player in the history - using content hash for stability
Â  Â  Â  Â  Â  Â  Â # Ensure audio is bytes for hashing
Â  Â  Â  Â  Â  Â  Â if isinstance(message['audio'], bytes):
Â  Â  Â  Â  Â  Â  Â  Â  Â audio_hash = base64.b64encode(message['audio']).decode('utf-8')[:10] # Simple hash for key
Â  Â  Â  Â  Â  Â  Â else:
Â  Â  Â  Â  Â  Â  Â  Â  Â audio_hash = "error" # Indicate issue if not bytes

Â  Â  Â  Â  Â  Â  Â try:
Â  Â  Â  Â  Â  Â  Â  Â  Â # Use the sample rate stored with the message if available, default to 44100
Â  Â  Â  Â  Â  Â  Â  Â  Â st.audio(message["audio"], format='audio/wav', sample_rate=message.get("sample_rate", 44100), key=f"audio_player_{audio_hash}")
Â  Â  Â  Â  Â  Â  Â except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â st.warning(f"Could not play audio: {e}") # Handle potential issues with st.audio


# Display recording status
status_placeholder = st.empty()
status_placeholder.info(f"Status: {st.session_state.recording_status}")

# Buttons to control recording
col1, col2 = st.columns(2)
with col1:
Â  Â  start_button = st.button("â–¶ï¸ Start Recording", key="voice_start_btn", disabled=st.session_state.is_recording)
with col2:
Â  Â  stop_button = st.button("â¹ï¸ Stop Recording", key="voice_stop_btn", disabled=not st.session_state.is_recording)


# --- webrtc_streamer component ---
# This component needs to be rendered for the audio stream to be available.
# It runs in the background and provides audio frames via the callback.
# Adding try/except block for robustness during initialization
try:
Â  Â  ctx = webrtc_streamer(
Â  Â  Â  Â  key="voice_agent_streamer_bottom",Â  # Unique key for this component instance
Â  Â  Â  Â  mode=WebRtcMode.SENDONLY,Â  # Send audio from browser to server
Â  Â  Â  Â  # Configuration previously in client_settings is now top-level parameters:
Â  Â  Â  Â  frontend_rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},Â  # Client-side WebRTC config
Â  Â  Â  Â  media_stream_constraints={"audio": True, "video": False},Â  # Media constraints (audio only)
Â  Â  Â  Â  audio_frame_callback=audio_frame_callback,Â  # Updated: Callback for processing audio frames
Â  Â  )
    # Handle potential issues with ctx.state.playing if needed - this runs in the main thread
    # if ctx.state.playing:
    #     # Logger can't be used here directly from the callback thread, but fine in main thread
    #     # logger.info("WebRTC streamer is playing.")
    #     pass # Add any logic needed when the streamer is active
    # else:
    #     # logger.info("WebRTC streamer not playing.")
    #     pass # Add any logic needed when the streamer is inactive (e.g., UI hints)

except Exception as e:
Â  Â  st.error(f"Failed to initialize voice agent microphone: {e}")
Â  Â  logger.exception("Error initializing webrtc_streamer for Voice Agent")
Â  Â  ctx = NoneÂ  # Set ctx to None if initialization fails


# Handle button clicks in the main Streamlit thread
if start_button:
Â  Â  # Check if webrtc_streamer is active before starting recording
Â  Â  if ctx and ctx.state.playing:
        st.session_state.is_recording = True
        # Ensure buffer is cleared and format info reset in a thread-safe way
        with st.session_state.audio_buffer_lock:
Â  Â          st.session_state.audio_buffer = [] # Clear buffer on start
Â  Â      st.session_state.pop('audio_format', None) # Clear format info on start
Â  Â      st.session_state.recording_status = "Recording..."
Â  Â      # No clearing chat history here, allowing for conversation
Â  Â      status_placeholder.info(f"Status: {st.session_state.recording_status}")
        st.rerun() # Rerun to update button states and status
    else:
        st.warning("Microphone stream is not active. Please allow microphone access and ensure the WebRTC component is initialized.")
        st.session_state.recording_status = "Idle" # Reset status
        status_placeholder.info(f"Status: {st.session_state.recording_status}")


if stop_button:
Â  Â  st.session_state.is_recording = False
Â  Â  st.session_state.recording_status = "Processing..."
Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  # Process the recorded audio after stopping
Â  Â  # Ensure buffer is processed in a thread-safe manner
    audio_frames_to_process = []
    with st.session_state.audio_buffer_lock:
        audio_frames_to_process = st.session_state.audio_buffer[:] # Get a copy of the buffer
        st.session_state.audio_buffer = [] # Clear buffer immediately after getting copy
    audio_format_info = st.session_state.pop('audio_format', {}) # Get and clear format info

    if audio_frames_to_process:
Â  Â  Â  Â  logger.info(f"Processing {len(audio_frames_to_process)} frames after stopping.")

Â  Â  Â  Â  # Convert frames to WAV bytes
Â  Â  Â  Â  wav_data = frames_to_wav_bytes(audio_frames_to_process) # Process the copied frames

Â  Â  Â  Â  if wav_data:
Â  Â  Â  Â  Â  Â  audio_base64 = base64.b64encode(wav_data).decode('utf-8')
Â  Â  Â  Â  Â  Â  logger.info(f"Encoded audio data to Base64, size: {len(audio_base64)} bytes.")

Â  Â  Â  Â  Â  Â  # --- Transcribe audio ---
Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Transcribing..."
Â  Â  Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")
Â  Â  Â  Â  Â  Â  with st.spinner("Transcribing audio..."):
Â  Â  Â  Â  Â  Â  Â  Â  transcription_payload = {"audio_base64": audio_base64}
Â  Â  Â  Â  Â  Â  Â  Â  # Use make_api_request with endpoint key
Â  Â  Â  Â  Â  Â  Â  Â  transcription_response = make_api_request("POST", "voice_transcribe", transcription_payload)

Â  Â  Â  Â  Â  Â  user_text = "Could not transcribe audio."
            transcription_error = False
Â  Â  Â  Â  Â  Â  if "error" not in transcription_response:
Â  Â  Â  Â  Â  Â  Â  Â  user_text = transcription_response.get("transcription", user_text)
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Transcription Complete."
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  user_text = f"Transcription Error: {transcription_response['error']}"
                transcription_error = True
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Transcription Error."
Â  Â  Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  Â  Â  Â  Â  # Add user's transcription to chat history (only if valid)
Â  Â  Â  Â  Â  Â  if not transcription_error and user_text and user_text.strip() != "" and user_text != "Could not transcribe audio.":
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.chat_history.append({"role": "user", "content": user_text})

Â  Â  Â  Â  Â  Â  # --- Send transcription to Gemini Chat ---
Â  Â  Â  Â  Â  Â  ai_response_text = ""
Â  Â  Â  Â  Â  Â  ai_response_audio = None # To store TTS audio bytes

Â  Â  Â  Â  Â  Â  # Only send to Gemini if transcription was successful and has meaningful content
Â  Â  Â  Â  Â  Â  if not transcription_error and user_text and user_text.strip() != "" and user_text != "Could not transcribe audio.":
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Sending to Gemini..."
Â  Â  Â  Â  Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")
Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Getting response from Gemini..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Send the transcribed text to Gemini. The backend needs to interpret this.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gemini_payload = {"text": user_text}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Use make_api_request with endpoint key
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gemini_response = make_api_request("POST", "gemini_chat", gemini_payload)


Â  Â  Â  Â  Â  Â  Â  Â  if "error" not in gemini_response:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ai_response_text = gemini_response.get("response", "No response from Gemini.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Gemini Response Received."

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- Generate TTS for AI response ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ai_response_text: # Only generate TTS if there's text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Generating Speech..."
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â status_placeholder.info(f"Status: {st.session_state.recording_status}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â with st.spinner("Generating AI speech..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â tts_payload = {"text": ai_response_text}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Request raw audio bytes (return_json=False) from backend TTS endpoint
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Use make_api_request with endpoint key, request bytes
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â tts_response_data = make_api_request("POST", "tts", tts_payload, return_json=False) # <--- Use endpoint key

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â if not isinstance(tts_response_data, dict) or "error" not in tts_response_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Assuming tts_response_data is the raw WAV bytes
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_audio = tts_response_data
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Speech Generated."
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â logger.info(f"Received TTS audio bytes, size: {len(ai_response_audio) if ai_response_audio else 0}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Handle error if make_api_request returned an error dict
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_text += f"\n(TTS Error: {tts_response_data.get('error', 'Unknown TTS error')})" # Append TTS error to text response
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "TTS Error."

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "No AI text response for speech."

Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ai_response_text = f"Error from Gemini: {gemini_response['error']}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Gemini Error."

Â  Â  Â  Â  Â  Â  elif user_text.startswith("Transcription Error"):
Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_text = f"Could not process audio: {user_text}"
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Processing failed."
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â # Case where transcription was empty or "Could not transcribe audio."
Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_text = "Please try speaking again."
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Processing failed."


Â  Â  Â  Â  Â  Â  # Add AI's response (text and potentially audio) to chat history
Â  Â  Â  Â  Â  Â  if ai_response_text or ai_response_audio is not None: # Check explicitly for not None
Â  Â  Â  Â  Â  Â  Â  Â  # Include sample rate if known from audio format info for st.audio playback
Â  Â  Â  Â  Â  Â  Â  Â  Â ai_message = {"role": "ai", "content": ai_response_text, "audio": ai_response_audio}
Â  Â  Â  Â  Â  Â  Â  Â  Â if audio_format_info.get("sample_rate"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ai_message["sample_rate"] = audio_format_info["sample_rate"]
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.chat_history.append(ai_message)


Â  Â  Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.session_state.recording_status = "Failed to process audio."
Â  Â  Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  else:
Â  Â  Â  Â  st.session_state.recording_status = "No audio recorded."
Â  Â  Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  # Ensure buffer is cleared after processing
    with st.session_state.audio_buffer_lock:
Â  Â       st.session_state.audio_buffer = [] # Clear buffer after processing attempt
Â  Â  st.session_state.pop('audio_format', None) # Clear audio format info after processing attempt
Â  Â  # Trigger a rerun to update the chat history display
Â  Â  st.rerun()

# Add a simple text input as an alternative way to chat if mic is not preferred
st.markdown("---") # Separator before text input
text_query = st.text_input("Type your query here:", key="text_chat_input")
send_text_button = st.button("Send Text Query", key="send_text_btn")

if send_text_button and text_query:
    # Use make_api_request for the text query to the backend Gemini Chat endpoint
Â  Â  st.session_state.recording_status = "Processing Text Query..."
Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  user_text = text_query
Â  Â  # Add user's text to chat history immediately
Â  Â  st.session_state.chat_history.append({"role": "user", "content": user_text})


Â  Â  # --- Send text query to Gemini Chat ---
Â  Â  ai_response_text = ""
Â  Â  ai_response_audio = None # To store TTS audio bytes

Â  Â  st.session_state.recording_status = "Sending to Gemini..."
Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")
Â  Â  with st.spinner("Getting response from Gemini..."):
Â  Â  Â  Â  # Send the text query to Gemini. Backend interprets.
Â  Â  Â  Â  gemini_payload = {"text": user_text}
Â  Â  Â  Â  # Use make_api_request with the endpoint key
Â  Â  Â  Â  gemini_response = make_api_request("POST", "gemini_chat", gemini_payload) # <--- Use endpoint key


Â  Â  if "error" not in gemini_response:
Â  Â  Â  Â  ai_response_text = gemini_response.get("response", "No response from Gemini.")
Â  Â  Â  Â  st.session_state.recording_status = "Gemini Response Received."

Â  Â  Â  Â  # --- Generate TTS for AI response ---
Â  Â  Â  Â  if ai_response_text:
Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Generating Speech..."
Â  Â  Â  Â  Â  Â  Â status_placeholder.info(f"Status: {st.session_state.recording_status}")
Â  Â  Â  Â  Â  Â  Â with st.spinner("Generating AI speech..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â tts_payload = {"text": ai_response_text}
Â  Â  Â  Â  Â  Â  Â  Â  Â # Request raw audio bytes (return_json=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â # Use make_api_request with endpoint key, request bytes
Â  Â  Â  Â  Â  Â  Â  Â  Â tts_response_data = make_api_request("POST", "tts", tts_payload, return_json=False) # <--- Use endpoint key


Â  Â  Â  Â  Â  Â  Â if not isinstance(tts_response_data, dict) or "error" not in tts_response_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â # Assuming tts_response_data is the raw WAV bytes
Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_audio = tts_response_data
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "Speech Generated."
Â  Â  Â  Â  Â  Â  Â  Â  Â logger.info(f"Received TTS audio bytes, size: {len(ai_response_audio) if ai_response_audio else 0}")
Â  Â  Â  Â  Â  Â  Â else:
Â  Â  Â  Â  Â  Â  Â  Â  Â ai_response_text += f"\n(TTS Error: {tts_response_data.get('error', 'Unknown TTS error')})"
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "TTS Error."

Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â st.session_state.recording_status = "No AI text response for speech."

Â  Â  else:
Â  Â  Â  Â  ai_response_text = f"Error from Gemini: {gemini_response['error']}"
Â  Â  Â  Â  st.session_state.recording_status = "Gemini Error."


Â  Â  # Add AI's response (text and potentially audio) to chat history
Â  Â  if ai_response_text or ai_response_audio is not None: # Check explicitly for not None
Â  Â  Â  Â  # For text input, we don't have captured audio format info. Default sample rate is usually ok for st.audio.
Â  Â  Â  Â  st.session_state.chat_history.append({"role": "ai", "content": ai_response_text, "audio": ai_response_audio})


Â  Â  status_placeholder.info(f"Status: {st.session_state.recording_status}")

Â  Â  # Clear the text input after sending
Â  Â  st.session_state.text_chat_input = "" # Use the session state key
Â  Â  # Trigger a rerun to update the chat history display (only if text input was used)
Â  Â  st.rerun() # Rerun will happen anyway if button is pressed, but explicit for clarity

# === Debugging/Development Info (Optional) ===
# st.sidebar.markdown("---")
# st.sidebar.subheader("Debugging Info")
# st.sidebar.write(f"Backend URL: {BACKEND_URL}")
# st.sidebar.write(f"Active Issue ID: {st.session_state.get('active_issue_id', 'None')}")
# st.sidebar.write(f"Workflow Completed: {st.session_state.get('workflow_completed', 'False')}")
# # Display full session state (be cautious with sensitive data)
# # st.sidebar.json(st.session_state)
